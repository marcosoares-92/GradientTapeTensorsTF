{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "colab": {
            "name": "GradientTapeBasics.ipynb",
            "provenance": []
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Gradient Tape Basics\n",
                "\n",
                "In this ungraded lab, you'll get familiar with Tensorflow's built in API called Gradient Tape which helps in performing automatic differentiation."
            ],
            "metadata": {
                "azdata_cell_guid": "46c575ea-7f88-415f-aa84-b38e27fc7133"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Imports"
            ],
            "metadata": {
                "azdata_cell_guid": "478ab0c1-ee48-4bcd-aea6-9d358451fa84"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import tensorflow as tf"
            ],
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "uQe_MWjNPQkR",
                "azdata_cell_guid": "d0d1a5a0-4a22-4381-9a46-549be8d5eb07",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Exercise on basics of Gradient Tape\n",
                "\n",
                "Let's explore how you can use [tf.GradientTape()](https://www.tensorflow.org/api_docs/python/tf/GradientTape) to do automatic differentiation."
            ],
            "metadata": {
                "azdata_cell_guid": "b7af7997-e6aa-4172-acc9-3027ad2a48a3"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Define a 2x2 array of 1's\n",
                "x = tf.ones((2,2))\n",
                "\n",
                "with tf.GradientTape() as t:\n",
                "    # Record the actions performed on tensor x with `watch`\n",
                "    t.watch(x) \n",
                "\n",
                "    # Define y as the sum of the elements in x\n",
                "    y =  tf.reduce_sum(x)\n",
                "\n",
                "    # Let z be the square of y\n",
                "    z = tf.square(y) \n",
                "\n",
                "# Get the derivative of z wrt the original input tensor x\n",
                "dz_dx = t.gradient(z, x)\n",
                "\n",
                "# Print our result\n",
                "print(dz_dx)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 69
                },
                "colab_type": "code",
                "id": "57Vnn9iIPNh9",
                "outputId": "543fce75-1adc-447c-b70b-872e8f8c9841",
                "azdata_cell_guid": "cd8623b3-00cb-46ed-96b8-ca9c5f5c35ac",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "tf.Tensor(\n[[8. 8.]\n [8. 8.]], shape=(2, 2), dtype=float32)\n"
                }
            ],
            "execution_count": 2
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Gradient tape expires after one use, by default\n",
                "\n",
                "If you want to compute multiple gradients, note that by default, GradientTape is not persistent (`persistent=False`).  This means that the GradientTape will expire after you use it to calculate a gradient.\n",
                "\n",
                "To see this, set up gradient tape as usual and calculate a gradient, so that the gradient tape will be 'expired'."
            ],
            "metadata": {
                "azdata_cell_guid": "0efc5c83-b02d-436d-bb7f-bf0654263698"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "x = tf.constant(3.0)\n",
                "\n",
                "# Notice that persistent is False by default\n",
                "with tf.GradientTape() as t:\n",
                "    t.watch(x)\n",
                "    \n",
                "    # y = x^2\n",
                "    y = x * x\n",
                "    \n",
                "    # z = y^2\n",
                "    z = y * y\n",
                "\n",
                "# Compute dz/dx. 4 * x^3 at x = 3 --> 108.0\n",
                "dz_dx = t.gradient(z, x)\n",
                "print(dz_dx)"
            ],
            "metadata": {
                "azdata_cell_guid": "f6d3ebf7-47f6-4ce3-8a62-c3c0eb462153",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "tf.Tensor(108.0, shape=(), dtype=float32)\n"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Gradient tape has expired\n",
                "\n",
                "See what happens if you try to calculate another gradient after you've already used gradient tape once."
            ],
            "metadata": {
                "azdata_cell_guid": "007469bc-247f-486b-8c5d-f04a3b691567"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# If you try to compute dy/dx after the gradient tape has expired:\n",
                "try:\n",
                "    dy_dx = t.gradient(y, x)  # 6.0\n",
                "    print(dy_dx)\n",
                "except RuntimeError as e:\n",
                "    print(\"The error message you get is:\")\n",
                "    print(e)"
            ],
            "metadata": {
                "azdata_cell_guid": "ec98879a-d1b8-494b-9650-5bcca9775e5a",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "The error message you get is:\nGradientTape.gradient can only be called once on non-persistent tapes.\n"
                }
            ],
            "execution_count": 4
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Make the gradient tape persistent\n",
                "To make sure that the gradient tape can be used multiple times, set `persistent=True` "
            ],
            "metadata": {
                "azdata_cell_guid": "83709a03-9564-472b-a838-d3e2512f6de1"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "x = tf.constant(3.0)\n",
                "\n",
                "# Set persistent=True so that you can reuse the tape\n",
                "with tf.GradientTape(persistent=True) as t:\n",
                "    t.watch(x)\n",
                "    \n",
                "    # y = x^2\n",
                "    y = x * x\n",
                "    \n",
                "    # z = y^2\n",
                "    z = y * y\n",
                "\n",
                "# Compute dz/dx. 4 * x^3 at x = 3 --> 108.0\n",
                "dz_dx = t.gradient(z, x)\n",
                "print(dz_dx)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 52
                },
                "colab_type": "code",
                "id": "P12ExatAPqn6",
                "outputId": "65d8c2ca-b49d-4b91-d2d5-97153daf5d19",
                "azdata_cell_guid": "7822ed78-a93a-4b6f-904f-2caf3e2e5b47",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "tf.Tensor(108.0, shape=(), dtype=float32)\n"
                }
            ],
            "execution_count": 5
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Now that it's persistent, you can still reuse this tape!\n",
                "\n",
                "Try calculating a second gradient on this persistent tape."
            ],
            "metadata": {
                "azdata_cell_guid": "08d78bb9-eb43-4161-b000-0bd4627d6cd5"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# You can still compute dy/dx because of the persistent flag.\n",
                "dy_dx = t.gradient(y, x)  # 6.0\n",
                "print(dy_dx)"
            ],
            "metadata": {
                "azdata_cell_guid": "e624212c-6efc-467f-8b9c-b393d8b66eab",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "tf.Tensor(6.0, shape=(), dtype=float32)\n"
                }
            ],
            "execution_count": 6
        },
        {
            "cell_type": "markdown",
            "source": [
                "Great! It still works!  Delete the tape variable `t` once you no longer need it."
            ],
            "metadata": {
                "azdata_cell_guid": "59b7571f-9ba5-4ca9-90a6-8e295c761922"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Drop the reference to the tape\n",
                "del t  "
            ],
            "metadata": {
                "azdata_cell_guid": "717dad6d-a1fe-4ed1-a97d-970f7a73faed",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 7
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Nested Gradient tapes\n",
                "Now let's try computing a higher order derivative by nesting the `GradientTapes:`\n",
                "\n",
                "#### Acceptable indentation of the first gradient calculation\n",
                "Keep in mind that you'll want to make sure that the first gradient calculation of `dy_dx` should occur at least inside the outer `with` block."
            ],
            "metadata": {
                "azdata_cell_guid": "2ecb4ae1-af57-4f1f-b677-4575f3457069"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "x = tf.Variable(1.0)\n",
                "\n",
                "with tf.GradientTape() as tape_2:\n",
                "    with tf.GradientTape() as tape_1:\n",
                "        y = x * x * x\n",
                "    \n",
                "    # The first gradient calculation should occur at least\n",
                "    # within the outer with block\n",
                "    dy_dx = tape_1.gradient(y, x)\n",
                "d2y_dx2 = tape_2.gradient(dy_dx, x)\n",
                "\n",
                "print(dy_dx)\n",
                "print(d2y_dx2)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 52
                },
                "colab_type": "code",
                "id": "UxNLeFLlP4qU",
                "outputId": "5f96770a-f0a3-47e5-dd8d-3e0b3074deeb",
                "azdata_cell_guid": "24b02ef7-38a3-43f7-aa51-ec6ac229b359",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "tf.Tensor(3.0, shape=(), dtype=float32)\ntf.Tensor(6.0, shape=(), dtype=float32)\n"
                }
            ],
            "execution_count": 8
        },
        {
            "cell_type": "markdown",
            "source": [
                "The first gradient calculation can also be inside the inner with block."
            ],
            "metadata": {
                "azdata_cell_guid": "73312084-f7d2-4cd9-abae-6e6f3bad703d"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "x = tf.Variable(1.0)\n",
                "\n",
                "with tf.GradientTape() as tape_2:\n",
                "    with tf.GradientTape() as tape_1:\n",
                "        y = x * x * x\n",
                "    \n",
                "        # The first gradient calculation can also be within the inner with block\n",
                "        dy_dx = tape_1.gradient(y, x)\n",
                "d2y_dx2 = tape_2.gradient(dy_dx, x)\n",
                "\n",
                "print(dy_dx)\n",
                "print(d2y_dx2)"
            ],
            "metadata": {
                "azdata_cell_guid": "ac4ca475-3203-4a57-b72e-106a1882ecf8",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "tf.Tensor(3.0, shape=(), dtype=float32)\ntf.Tensor(6.0, shape=(), dtype=float32)\n"
                }
            ],
            "execution_count": 9
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Where not to indent the first gradient calculation\n",
                "If the first gradient calculation is OUTSIDE of the outer `with` block, it won't persist for the second gradient calculation."
            ],
            "metadata": {
                "azdata_cell_guid": "2e45f7e4-ac1e-4a27-bd23-47fb5d0a2ee0"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "x = tf.Variable(1.0)\n",
                "\n",
                "with tf.GradientTape() as tape_2:\n",
                "    with tf.GradientTape() as tape_1:\n",
                "        y = x * x * x\n",
                "\n",
                "# The first gradient call is outside the outer with block\n",
                "# so the tape will expire after this\n",
                "dy_dx = tape_1.gradient(y, x)\n",
                "\n",
                "# The tape is now expired and the gradient output will be `None`\n",
                "d2y_dx2 = tape_2.gradient(dy_dx, x)\n",
                "\n",
                "print(dy_dx)\n",
                "print(d2y_dx2)"
            ],
            "metadata": {
                "azdata_cell_guid": "d2df628a-0ad3-432b-9f37-bbdd0864c769",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "tf.Tensor(3.0, shape=(), dtype=float32)\nNone\n"
                }
            ],
            "execution_count": 10
        },
        {
            "cell_type": "markdown",
            "source": [
                "Notice how the `d2y_dx2` calculation is now `None`.  The tape has expired.  Also note that this still won't work even if you set persistent=True for both gradient tapes."
            ],
            "metadata": {
                "azdata_cell_guid": "6813d9db-a1a4-4b26-bd26-d83a56e61a6c"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "x = tf.Variable(1.0)\n",
                "\n",
                "# Setting persistent=True still won't work\n",
                "with tf.GradientTape(persistent=True) as tape_2:\n",
                "    # Setting persistent=True still won't work\n",
                "    with tf.GradientTape(persistent=True) as tape_1:\n",
                "        y = x * x * x\n",
                "\n",
                "# The first gradient call is outside the outer with block\n",
                "# so the tape will expire after this\n",
                "dy_dx = tape_1.gradient(y, x)\n",
                "\n",
                "# the output will be `None`\n",
                "d2y_dx2 = tape_2.gradient(dy_dx, x)\n",
                "\n",
                "print(dy_dx)\n",
                "print(d2y_dx2)"
            ],
            "metadata": {
                "azdata_cell_guid": "3cae5952-7b52-47bb-8813-3cb7320087c4",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "tf.Tensor(3.0, shape=(), dtype=float32)\nNone\n"
                }
            ],
            "execution_count": 11
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Proper indentation for the second gradient calculation\n",
                "\n",
                "The second gradient calculation `d2y_dx2` can be indented as much as the first calculation of `dy_dx` but not more."
            ],
            "metadata": {
                "azdata_cell_guid": "fa3f1db0-f2fc-40ef-9060-01dfcfb8d99c"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "x = tf.Variable(1.0)\n",
                "\n",
                "with tf.GradientTape() as tape_2:\n",
                "    with tf.GradientTape() as tape_1:\n",
                "        y = x * x * x\n",
                "\n",
                "        dy_dx = tape_1.gradient(y, x)\n",
                "        \n",
                "        # this is acceptable\n",
                "        d2y_dx2 = tape_2.gradient(dy_dx, x)\n",
                "\n",
                "print(dy_dx)\n",
                "print(d2y_dx2)"
            ],
            "metadata": {
                "azdata_cell_guid": "99591c77-0a3b-41f5-829a-2a65bde76d04",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "tf.Tensor(3.0, shape=(), dtype=float32)\ntf.Tensor(6.0, shape=(), dtype=float32)\n"
                }
            ],
            "execution_count": 12
        },
        {
            "cell_type": "markdown",
            "source": [
                "This is also acceptable"
            ],
            "metadata": {
                "azdata_cell_guid": "b6838122-750b-4985-b14c-3a5328a9c33c"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "x = tf.Variable(1.0)\n",
                "\n",
                "with tf.GradientTape() as tape_2:\n",
                "    with tf.GradientTape() as tape_1:\n",
                "        y = x * x * x\n",
                "\n",
                "        dy_dx = tape_1.gradient(y, x)\n",
                "        \n",
                "    # this is also acceptable\n",
                "    d2y_dx2 = tape_2.gradient(dy_dx, x)\n",
                "\n",
                "print(dy_dx)\n",
                "print(d2y_dx2)"
            ],
            "metadata": {
                "azdata_cell_guid": "bab5f5a2-534c-4674-9f2f-56cbcdeda069",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "tf.Tensor(3.0, shape=(), dtype=float32)\ntf.Tensor(6.0, shape=(), dtype=float32)\n"
                }
            ],
            "execution_count": 13
        },
        {
            "cell_type": "markdown",
            "source": [
                "This is also acceptable"
            ],
            "metadata": {
                "azdata_cell_guid": "70a5ffd7-11c2-4d03-ba9e-7c3aa39aae36"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "x = tf.Variable(1.0)\n",
                "\n",
                "with tf.GradientTape() as tape_2:\n",
                "    with tf.GradientTape() as tape_1:\n",
                "        y = x * x * x\n",
                "\n",
                "        dy_dx = tape_1.gradient(y, x)\n",
                "        \n",
                "# this is also acceptable\n",
                "d2y_dx2 = tape_2.gradient(dy_dx, x)\n",
                "\n",
                "print(dy_dx)\n",
                "print(d2y_dx2)"
            ],
            "metadata": {
                "azdata_cell_guid": "45b783a5-35f2-4e94-bf15-5f1fe4beffbf",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "tf.Tensor(3.0, shape=(), dtype=float32)\ntf.Tensor(6.0, shape=(), dtype=float32)\n"
                }
            ],
            "execution_count": 14
        },
        {
            "cell_type": "code",
            "source": [],
            "metadata": {
                "azdata_cell_guid": "9aef33f5-540a-43d6-b6cc-46189e1f7df7",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}